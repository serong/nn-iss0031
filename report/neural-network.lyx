#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass report
\begin_preamble

                                                     
% Code color ------
\usepackage{color}
 
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\newcommand*{\vUniversity}{TALLINN UNIVERSITY OF TECHNOLOGY}
\newcommand*{\vFaculty}{Faculty of Information Technology}
\newcommand*{\vDepartment}{Department of Computer Control}
\newcommand*{\vChair}{Chair of Automatic Control and Systems Analysis}

\newcommand*{\vAuthor}{Serkan Ongan}
\newcommand*{\vAuthorCode}{156395IASM}
\newcommand*{\vReportName}{Digit Recognition Using Neural Network Implemented in Python }
\newcommand*{\vClass}{ISS0031 Modelling and Identification}
\newcommand*{\vSupervisor}{Aleksei Tepljakov}
\end_preamble
\use_default_options true
\begin_modules
theorems-ams
theorems-chap
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman times
\font_sans default
\font_typewriter default
\font_default_family rmdefault
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 12
\spacing other 1.3
\use_hyperref false
\papersize a4paper
\use_geometry true
\use_amsmath 2
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 30mm
\topmargin 25mm
\rightmargin 30mm
\bottommargin 25mm
\secnumdepth 2
\tocdepth 2
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\listings_params "backgroundcolor={\color{backcolour}},basicstyle={\footnotesize},breakatwhitespace=false,breaklines=true,captionpos=b,commentstyle={\color{codegreen}},keepspaces=true,keywordstyle={\color{magenta}},numbers=left,numbersep=5pt,numberstyle={\tiny\color{codegray}},showspaces=false,showstringspaces=false,showtabs=false,stringstyle={\color{codepurple}},tabsize=2"
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{titlepage}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing single
\align center
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vUniversity 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
vFaculty
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace 1.5in*
\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing onehalf
\align center
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vAuthor 
\backslash
 
\end_layout

\end_inset

 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vAuthorCode
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace 0.2in*
\end_inset


\end_layout

\begin_layout Standard
\align center

\series bold
\size larger
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
scshape{
\backslash
vReportName}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing single
\align center
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vClass
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace 1.2in
\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing single
\noindent
\align right
Supervisor: 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vSupervisor
\end_layout

\end_inset


\size large
 
\end_layout

\begin_layout Standard
\begin_inset VSpace 3.1in
\end_inset


\end_layout

\begin_layout Standard
\align center

\size large
Tallinn 2016 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{titlepage}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
pagenumbering{roman} 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset FloatList figure

\end_inset


\end_layout

\begin_layout Standard
\begin_inset FloatList table

\end_inset


\end_layout

\begin_layout Chapter*
Abstract
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
addcontentsline{toc}{chapter}{Abstract}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
This project takes a brief look into neural network as modelling tools,
 as well as their implementation in Python programming language.
 Therefore it includes both theoretical and practical information in those
 areas.
 
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Chapter
Introduction
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
pagenumbering{arabic} 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
// Some things about why neural networks are important.
 Teaching tools, data complexity and vast amount of data.
 
\end_layout

\begin_layout Standard
// And the need to use more open sourced alternative to make the teaching
 and learning more ??? as well as taking a deeper look into the subject
 beyond using ready made function.
\end_layout

\begin_layout Section
Aim of the project
\end_layout

\begin_layout Standard
// Aim of the project and so on.
\end_layout

\begin_layout Section
Approach
\end_layout

\begin_layout Standard
// Deeper look into NN and getting familiar in 
\end_layout

\begin_layout Section
Choices
\end_layout

\begin_layout Standard
// Library choice which will be discussed more thoroughly in the later chapters.
\end_layout

\begin_layout Chapter
Neural Networks
\end_layout

\begin_layout Standard
In this chapter, we take a brief technical look at neural networks in order
 to lay the foundations of the actual Python implementation of the project.
\end_layout

\begin_layout Section
Biological Model
\end_layout

\begin_layout Standard
Taking a look at the biological model that inspired artificial neural networks
 can help us understand their structure better.
 But since the biological model of how neuron and brain work is highly complex,
 I think it's beneficial to take a brief look at it.
\end_layout

\begin_layout Standard
A typical neuron can be thought as a signal processing device.
 
\begin_inset CommandInset citation
LatexCommand cite
key "book:gurney"

\end_inset

 This happens through positively or negatively charged ions.
 Each neuron is connected many others via synapses.
 Inputs to the neuron summed up and if it's over a certain threshold the
 neuron is excited.
 In general, an neuron can excited or inhibited.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Neuron structure.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename images/neuron_structure.jpg

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
This basic model is very close to how a TLU (threshold logic unit) works,
 which will be discussed in the next section.
\end_layout

\begin_layout Standard
Human brain includes roughly over 
\series bold
100 trillion
\series default
 such connections, which forms the basis of how we learn new things and
 remember.
 A neural network is formed of simplified version of biological neurons
 and their connections, and are capable of making approximations for given
 data, after necessary training.
\end_layout

\begin_layout Section
Basic Theory
\end_layout

\begin_layout Standard
To give a formal definition, an artificial neural network is an assembly
 of interconnected simple processing elements (nodes), whose functionality
 is stored in the interconnections' strengths (weights).
 
\begin_inset CommandInset citation
LatexCommand cite
key "book:gurney"

\end_inset

 
\end_layout

\begin_layout Standard
Smallest element of a neural network is a node.
 Taking a look at TLU, a basic node structure, could make understanding
 how neural networks work easier.
\end_layout

\begin_layout Subsection
Threshold Logic Unit
\end_layout

\begin_layout Standard
A TLU unit can be explained as below.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
A TLU
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename images/tlu.png
	scale 75

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In this above example, the sum of weighted inputs is called 
\series bold
activation.
 Activation function
\series default
 (a unit step function in this case) takes this activation and the node's
 bias (
\begin_inset Formula $\theta$
\end_inset

) and produces an output accordingly.
 So the output of a node depends on the weights, inputs, bias and the activation
 function type.
 
\end_layout

\begin_layout Subsection
Activation Functions 
\end_layout

\begin_layout Standard
Activation functions affect the way node produces outputs, meaning they
 also affect the way information flows through the layers of the neural
 network.
 So we need to choose activation functions according to our goal and network
 structure.
 
\end_layout

\begin_layout Standard
For example, a sigmoid function would be a better choice if derivations
 come into the equation.
 Two most used activation functions are hyperbolic tangent (eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:hyperbolic"

\end_inset

) and sigmoid functions (eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:sigmoid"

\end_inset

).
 
\begin_inset CommandInset citation
LatexCommand cite
key "book:heaton"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
f(x)=\frac{e^{2x}-1}{e^{2x}+1}\label{eq:hyperbolic}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
f(x)=\frac{1}{1+e^{-x}}\label{eq:sigmoid}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
sigmoid (left) and hyperbolic tangent functions.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename images/sigmoid.jpeg
	scale 50

\end_inset


\begin_inset space \quad{}
\end_inset


\begin_inset Graphics
	filename images/tanh.jpeg
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Another important activation function is called 
\series bold
Softmax
\series default
 which is mostly used in the output layer to give output as a probability.
 More precisely it produces a K sized vector of real values in the range
 of (0,1) that add up to 1 when summed.
\end_layout

\begin_layout Standard
This is helpful in tasks like digit recognition where the output layer size
 is bigger than 1.
\end_layout

\begin_layout Subsection
Layers
\end_layout

\begin_layout Standard
After nodes, the next structure in a network is layers.
 A neural network has two special layers.
 Input and output layers, which depend on the data structure.
 The actual inner structure of the neural network depends on hidden layers
 between input and output layers, which effect the number of weights and
 therefore directly the training time of the network.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
A neural network with 2 hidden layers.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename images/neural_net.jpeg
	scale 50

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Training
\end_layout

\begin_layout Standard
A neural network gives us a model derived from a set of collected input
 and output.
 But to achieve this, we need to 
\series bold
train
\series default
 the neural network.
 For neural networks, training means altering weights and biases inside
 the network according to the error in the each iteration of the training.
\end_layout

\begin_layout Standard
Training dataset includes an input and an output for each example.
 During training the training data input is fed to the neural network and
 its output is compared to the training data output.
 With this comparison we acquire an error, and the objective of training
 is minimizing this error.
\end_layout

\begin_layout Standard
So in its basics, training is optimization of error for the neural network.
\end_layout

\begin_layout Subsection
Cost function
\end_layout

\begin_layout Standard
Cost function can be thought as the objective function in generic optimization
 problems.
 It is a representation of the global error in the network and a measurement
 of how well a neural network performs to the entire training dataset.
 It also depends on weights and biases.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
C=F(w,\theta)
\end{equation}

\end_inset


\begin_inset Formula 
\begin{equation}
C\rightarrow min
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
There are several differents methods for cost function.
 But some basic cost functions are:
\end_layout

\begin_layout Enumerate
Sum of square errors
\end_layout

\begin_layout Enumerate
Mean square errors
\end_layout

\begin_layout Enumerate
Root mean square
\end_layout

\begin_layout Standard
Although it should be noted that MSE is one of the most common cost functions
 used in neural networks.
 But there are exceptions, like the Levenberg Marquardt Algorithm requiring
 SSE.
 
\begin_inset CommandInset citation
LatexCommand cite
key "book:heaton"

\end_inset

 
\end_layout

\begin_layout Standard
A 
\series bold
linear error
\series default
 is simply the difference of ideal output (i) and actual output (a).
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
E=(i-a)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\series bold
MSE 
\series default
(mean square error) as mentioned before is the most common cost function.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
MSE=\frac{1}{n}\sum_{i=1}^{n}E^{2}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard

\series bold
SSE
\series default
 (sum of square errors) can be seen below.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
SSE=\frac{1}{2}\sum_{p}E^{2}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
And 
\series bold
RMS 
\series default
(root mean square) function is very close to MSE.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
RMS=\sqrt{\frac{1}{n}\sum_{i=1}^{n}E^{2}}
\end{equation}

\end_inset


\end_layout

\begin_layout Subsection
Optimization
\end_layout

\begin_layout Standard
The aim of the training is to minimize the cost function.
 For this optimization methods are used.
 One way to optimize the cost function is to use gradient descent.
\end_layout

\begin_layout Standard
Gradient descent is a menans of taking a step in the direction that does
 the most to decrease our cost function.
 We use derivatives to decide which way to take a small step in order to
 make the cost function smaller.
 Derivatives can give us an idea about the slope of the point we're at in
 the cost function, and like a ball following a slope down, we can follow
 it.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Gradient descent on error function.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename images/descent.png

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
For example, for C that 
\begin_inset Formula $C(v_{1},v_{2})$
\end_inset

, making small changes in 
\begin_inset Formula $v_{1}$
\end_inset

 and 
\begin_inset Formula $v_{2}$
\end_inset

 would cause a small changes in C.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\triangle C\equiv\frac{\delta C}{\delta v_{1}}\triangle v_{1}+\frac{\delta C}{\delta v_{2}}v_{2}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\triangle v=\left[\begin{array}{c}
\triangle v_{1}\\
\triangle v_{2}
\end{array}\right]\; and\;\nabla C=\left[\begin{array}{c}
\frac{\delta C}{\delta v_{1}}\\
\frac{\delta C}{\delta v_{2}}
\end{array}\right]
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The amount of we need to take to make C smaller can be calculated as the
 following formula, where 
\begin_inset Formula $\eta$
\end_inset

 is the learning rate and 
\begin_inset Formula $\eta>0$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\triangle v=-\eta\nabla C
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
But our initial starting point can make the optimization stop in a local
 minimum, and for that reason it's sometimes a good idea to train the network
 with different starting points.
\end_layout

\begin_layout Subsubsection
- Some optimization methods: 
\end_layout

\begin_layout Enumerate

\emph on
Backpropogation method:
\emph default
 A very common gradient descent based method.
 It requires a desired output for each input value, therefore it's more
 of a supervised learning tool.
 Gradient descent based methods often find the best solution within their
 starting point, so achieving a global result (finding the global minimum)
 is often has randomness to it.
\end_layout

\begin_layout Enumerate

\emph on
Genetic algorithm:
\emph default
 It is a global optimization method.
 Since it searches in many directions, the probability of finding a global
 minimum increases.
 And it makes it a very efficient tool for difficult non-linear functions.
\end_layout

\begin_layout Enumerate
Simulated annealing: SA is based on physical annealing process where physical
 substances go from a higher state of energy to a smaller one.
 A concrete example is heating metal to molten state and letting it slowly
 cooldown until it becomes solid again.
 An in application to neural networks, one distinct difference is that SA
 depends on user defined parameters in contrast to GA's dynamically assigned
 ones.
 Also it permits increasing 
\begin_inset Quotes eld
\end_inset

energy state
\begin_inset Quotes erd
\end_inset

, meaning accepting points on cost function with higher error values.
 This helps escaping local minimimums.
 
\begin_inset CommandInset citation
LatexCommand cite
key "bib:annealing"

\end_inset


\end_layout

\begin_layout Section
Classification
\end_layout

\begin_layout Section
Advantages
\end_layout

\begin_layout Chapter
Python
\end_layout

\begin_layout Standard
This chapter includes information about certain Python libraries that offer
 tools to implement neural networks, and the reasoning behind my choices
 regarding the implementation.
 It concludes with a section about the comparison of using computer vision
 solution instead of neural networks.
\end_layout

\begin_layout Section
Language and Libraries
\end_layout

\begin_layout Standard
Python is a high level scripting language that supports several programming
 paradigms, including procedural and object-oriented, as well as a partial
 support for functional programming (although not officially supported or
 encouraged).
 This makes it a very flexible tool to use in different application areas.
\end_layout

\begin_layout Standard
Another advantage of Python is that it has a clear and almost pseudo-code
 like syntax, making it easier to read and code.
 Below can be seen some examples of the syntax.
 Also appended to the file in Appendix 1 (page 
\begin_inset CommandInset ref
LatexCommand pageref
reference "chap:Appendix-1:-Code"

\end_inset

) are all the codes used in the implementation.
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "language=Python"
inline false
status open

\begin_layout Plain Layout

\begin_inset Caption

\begin_layout Plain Layout
Python programming language.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

# function definition ####################################################
\end_layout

\begin_layout Plain Layout

def function_name(args):
\end_layout

\begin_layout Plain Layout

	""" Function documentation.
\end_layout

\begin_layout Plain Layout

	"""
\end_layout

\begin_layout Plain Layout

	return value
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

# List comprehensions: ###################################################
\end_layout

\begin_layout Plain Layout

# a fast and convenient way to create lists.
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

[x for x in range(1,10)]
\end_layout

\begin_layout Plain Layout

#[1, 2, 3, 4, 5, 6, 7, 8, 9] 
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

[x*x for x in range(1,10)] 
\end_layout

\begin_layout Plain Layout

# [1, 4, 9, 16, 25, 36, 49, 64, 81] 
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

# Class definition.
 ######################################################
\end_layout

\begin_layout Plain Layout

class NeuralNetwork(object):     
\end_layout

\begin_layout Plain Layout

	bias_filename = "biases.npy"     
\end_layout

\begin_layout Plain Layout

	weights_filename = "weights.npy"
\end_layout

\begin_layout Plain Layout

    
\end_layout

\begin_layout Plain Layout

	def __init__(self, layers):         
\end_layout

\begin_layout Plain Layout

	""" Initialization.
 """
\end_layout

\begin_layout Plain Layout

		self.number_of_layers = len(layers)
\end_layout

\begin_layout Plain Layout

		self.layers = layers
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	def save_state():
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Being popular and open-sourced, the language has plenty of libraries (roughly
 90000 libraries)
\begin_inset CommandInset citation
LatexCommand cite
key "ref:pypi"

\end_inset

 and it is a widely used tool in scientific programming area.
\end_layout

\begin_layout Standard
During the research and implementation, I have looked into following libraries.
\end_layout

\begin_layout Subsection*
NumPy
\end_layout

\begin_layout Standard
NumPy is one of the fundamental scientific packages in Python.
 
\begin_inset CommandInset citation
LatexCommand cite
key "ref:numpy"

\end_inset

It offers powerful N-dimensional objects and tools for integrating with
 C/C++ and Fortran code, which make it possible to solve performance issues
 using lower level languages that are more performant.
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "language=Python"
inline false
status open

\begin_layout Plain Layout

\begin_inset Caption

\begin_layout Plain Layout
Very brief look into NumPy
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

# very brief look into numpy.
\end_layout

\begin_layout Plain Layout

import numpy as np
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

# creating a vector of 4 elements.
\end_layout

\begin_layout Plain Layout

vector_4 = np.random.randn(4)
\end_layout

\begin_layout Plain Layout

# array([ 0.00695554, -0.28457662,  2.36434078, -0.05432569]) 
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

# reshaping into a 2x2 matrix.
\end_layout

\begin_layout Plain Layout

vector_2x2 = vector_4.reshape(2,2)
\end_layout

\begin_layout Plain Layout

# array([[ 0.00695554, -0.28457662],        
\end_layout

\begin_layout Plain Layout

#        [ 2.36434078, -0.05432569]]) 
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
When compared to 
\series bold
Matlab
\series default
, there are fundamental differences.
\end_layout

\begin_layout Enumerate
Basic type in NumPy are multidimensional arrays, and operations on these
 arrays are 
\bar under
element-wise
\bar default
.
 If matrix-like operations are needed, a sub-type called 
\series bold
matrix
\series default
 type should be used.
\end_layout

\begin_layout Enumerate
Python arrays are 0-indexed, so the first element of an array A can be reached
 by A[0].
\end_layout

\begin_layout Enumerate
Better support for GUI applications via Python's general purpose programming
 approach.
\end_layout

\begin_layout Enumerate
In contrast to Matlab, arrays have pass-by-reference semantic.
\end_layout

\begin_layout Standard
It should also be noted that official advice of the library is to use 
\series bold
arrays
\series default
 instead of the 
\series bold
matrix
\series default
 sub-type.
 While matrices behave more-or-less like Matlab matrices, they have disadvantage
s like having maximum 2 dimensions.
 More information about NumPy equivalents of Matlab operations can be found
 at the documentation page of the library.
 
\begin_inset CommandInset citation
LatexCommand cite
key "ref:numpyDOC"

\end_inset


\end_layout

\begin_layout Subsection*
Matplotlib
\end_layout

\begin_layout Standard
Matplotlib is an open-source 2-D plotting library that is widely used by
 Python applications.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
A sample graph generated by Matplotlib
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename images/matplot_log.png
	scale 50

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection*
TensorFlow
\end_layout

\begin_layout Standard
TensorFlow is an open-source library that was developed within Google's
 Machine Intelligence research organization, as a tool to make research
 in machine learning quicker and easier to transition from prototype to
 production.
 
\begin_inset CommandInset citation
LatexCommand cite
key "ref:tensor"

\end_inset

 
\end_layout

\begin_layout Standard
TensorFlow is a system where you represent computations as graphs.
 Each operation (node) on the flow takes 
\series bold
tensors
\series default
.
 (In TensorFlow, a tensor is mainly a multi-dimensional array with static
 type and dynamic dimensions.) And each operation produces zero or more tensors.
\end_layout

\begin_layout Subsubsection*
- Features: 
\end_layout

\begin_layout Standard
Some important aspects of Tensorflow:
\end_layout

\begin_layout Enumerate
Backed by Google.
\end_layout

\begin_layout Enumerate
Good documentation, but complex.
\end_layout

\begin_layout Enumerate
Multi GPU support.
\end_layout

\begin_layout Enumerate
Distributed training.
\end_layout

\begin_layout Enumerate
Model checkpoints allows for pausing the training, evaluating and continuing
 from the checkpoint.
\end_layout

\begin_layout Subsection*
PyBrain
\end_layout

\begin_layout Standard
PyBrain is short for 
\emph on
Python-Based Reinforcement Learning, Artificial Intelligence and Neural
 Network Library
\emph default
, and it's a modular tool that offers easy to use algoritms for machine
 learning operations.
 They aim to be a library that can be used both entry-level students and
 researchers, so providing a less dense alternative to libraries like TensorFlow.
\end_layout

\begin_layout Subsubsection*
- Features: 
\end_layout

\begin_layout Enumerate
Support for standard and advanced algorithms in many areas of machine intelligen
ce.
 (Supervised and unsupervised learning, reinforcement learning, optimizations,
 neural networks, plotting etc.)
\end_layout

\begin_layout Enumerate
Allows complex architectures.
\end_layout

\begin_layout Subsection*
Theano
\end_layout

\begin_layout Standard
Theano is developed in University of Montreal's Institute of Learning Algorithms.
 It's used in the university's research as well as its machine learning
 classes.
 
\end_layout

\begin_layout Standard
In general, it's a library used to define, optimize and evaluate expression
 related to multi-dimensional arrays.
 
\begin_inset CommandInset citation
LatexCommand cite
key "ref:theano"

\end_inset

 
\end_layout

\begin_layout Subsubsection*
- Features: 
\end_layout

\begin_layout Enumerate
NumPy integration
\end_layout

\begin_layout Enumerate
Faster operations with GPU usage.
\end_layout

\begin_layout Enumerate
Efficient derivations
\end_layout

\begin_layout Enumerate
Extensive testing suite.
\end_layout

\begin_layout Standard
If offers speeds closer to compiled C code implementations, and it comes
 with several optimizations for symbolic expressions.
 ( 
\begin_inset Formula $x*y/y->x$
\end_inset

 )
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "language=Python"
inline false
status open

\begin_layout Plain Layout

\begin_inset Caption

\begin_layout Plain Layout
Code sample
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

import theano 
\end_layout

\begin_layout Plain Layout

from theano import tensor
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

a = tensor.dscalar() 
\end_layout

\begin_layout Plain Layout

b = tensor.dscalar()
\end_layout

\begin_layout Plain Layout

c = a + b
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

f = theano.function([a,b], c)
\end_layout

\begin_layout Plain Layout

assert 4.0 == f(1.5, 2.5)
\end_layout

\end_inset


\end_layout

\begin_layout Subsection*
ScikitLearn
\end_layout

\begin_layout Standard
Scikit-Learn is a machine learning library built upon NumPy, SciPy and matplotli
b libraries.
 It can handle both supervised and unsupervised learning, and supports following
 tasks:
\end_layout

\begin_layout Enumerate
Classification
\end_layout

\begin_layout Enumerate
Regression
\end_layout

\begin_layout Enumerate
Clustering
\end_layout

\begin_layout Enumerate
Dimensionality reduction
\end_layout

\begin_layout Enumerate
Model selection
\end_layout

\begin_layout Enumerate
Data preprocessing
\end_layout

\begin_layout Standard
Its advantage lies in the fact that it has extensive documentation and a
 lot of contribution from experts in machine learning field.
 It also provides a consisten interface to most machine learning tasks in
 a single library.
 
\begin_inset CommandInset citation
LatexCommand cite
key "ref:scikitWhy"

\end_inset


\end_layout

\begin_layout Subsection*
Keras
\end_layout

\begin_layout Standard
Keras is a library dedicated to neural network tasks.
 It can run on TensorFlow or Theano libraries, therefore providing their
 advantages like speed, GPU usage and so on.
 Its focus is on being a library that enables fast experimentations.
 
\begin_inset CommandInset citation
LatexCommand cite
key "ref:keras"

\end_inset


\end_layout

\begin_layout Subsubsection*
- Features: 
\end_layout

\begin_layout Enumerate
Supports both convolutional and recurrent neural networks, as well as combinatio
n of both.
\end_layout

\begin_layout Enumerate
GPU support.
\end_layout

\begin_layout Enumerate
Fast prototyping.
\end_layout

\begin_layout Enumerate
Minimalist.
\end_layout

\begin_layout Subsection*
Libraries with Python Bindings
\end_layout

\begin_layout Standard
In addition to the above libraries, there are libraries that were written
 in other languages but offers Python bindings:
\end_layout

\begin_layout Enumerate
FANN: Fast Artificial Neural Network Library
\end_layout

\begin_layout Enumerate
Caffe
\end_layout

\begin_layout Enumerate
mxnet
\end_layout

\begin_layout Section
Computer Vision Alternative (OpenCV)
\end_layout

\begin_layout Standard
Another approach to digit recognition can be done using a computer vision
 library like OpenCV.
 OpenCV is a cross-platform computer vision library that offers interface
 for Java, C++, Python and C.
 It's possible to use classifiers like k-nearest neighbor, support vector
 machine and random forest.
\end_layout

\begin_layout Standard
MNIST database offers a list of machine learning tools and their performances
 on the MNIST datasets.
 This can give us an idea about the comparison between neural network and
 some methods used in computer vision.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Method comparison.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace medskip*
\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="2">
<features tabularvalignment="middle">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Methods
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Test Error Range
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Neural Networks
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
% 0.35 - 4.7
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Convolutional Networks
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
% 0.23 - 1.7
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
K-Nearest Neighbor
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
% 0.52 - 5.0
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Support Vector Machines
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
% 0.56 - 1.4
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Chapter
Implementation
\end_layout

\begin_layout Section
Data
\end_layout

\begin_layout Standard
The data used in the project was acquired at the Modified NIST database
 
\begin_inset CommandInset citation
LatexCommand cite
key "ref:mnist"

\end_inset

, which is a subset of a larger study done at the National Institute of
 Standards and Technology of United States of America.
\end_layout

\begin_layout Standard
It is preprocessed and formatted, therefore offering a good learning tool.
\end_layout

\begin_layout Subsection*
Data preparation and format
\end_layout

\begin_layout Standard
Each digit image was center in 28x28 pixel format and later transformed
 into a vector.
 Each vector element represents a pixel in the image in the form of 
\series bold
blackness
\series default
 of the said pixel.
 Also each image was labeled in the form of vector with a size of 10.
\end_layout

\begin_layout Subsection*
Input
\end_layout

\begin_layout Standard
Each input to the neural network will be in the form a vector (784x1).
 A sample input if represented as a 28x28 matrix could look as follows:
\end_layout

\begin_layout Standard
\begin_inset Float table
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Number matrix representation
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace smallskip
\end_inset


\end_layout

\begin_layout Plain Layout
\paragraph_spacing double
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="5">
<features tabularvalignment="middle">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
R/C
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
...
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
28
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
...
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
...
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.7
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
...
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
28
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
...
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
And if plotted according to each pixel's blackness value, such a number
 could look as follows:
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Number visual representation
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename images/number_rep.png
	scale 50

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection*
Output
\end_layout

\begin_layout Standard
Each number in the set is also labelled by a vector of (10x1) size.
 So, for example label for the above number would be:
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "language=Python"
inline false
status open

\begin_layout Plain Layout

\begin_inset Caption

\begin_layout Plain Layout
Vector for number 4 in Python script
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

# Vector for number 4
\end_layout

\begin_layout Plain Layout

number_4 = [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]
\end_layout

\end_inset


\end_layout

\begin_layout Subsection*
Datasets
\end_layout

\begin_layout Standard
The dataset comes with a training set of 60000 examples and a test set of
 10000 examples.
 For the project training set was partioned into 50000 examples for training
 and 10000 examples for validation.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Datasets
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace medskip
\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="3">
<features tabularvalignment="middle">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Dataset
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Inputs
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Labels
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
training dataset
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
50000
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
50000
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
validation dataset
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
10000
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
10000
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
testing dataset
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
10000
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
10000
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
The Neural Network 
\end_layout

\begin_layout Subsection
Layers
\end_layout

\begin_layout Subsection
Cost Function
\end_layout

\begin_layout Subsection
Optimization Method
\end_layout

\begin_layout Subsection
Training
\end_layout

\begin_layout Subsection
Performance
\end_layout

\begin_layout Chapter
Conclusion
\end_layout

\begin_layout Standard
Last words.
\end_layout

\begin_layout Chapter*
Appendix 1: Code
\begin_inset CommandInset label
LatexCommand label
name "chap:Appendix-1:-Code"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
addcontentsline{toc}{chapter}{Appendix 1: Lyx}
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
Here can be found the code used during the practical implementation.
 An updated copy of the code can also be found at the following Github repositor
y, which includes this report as well as the datasets and Python scripts
 used.
\end_layout

\begin_layout Standard
/// Github linkç
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ref:mnist"

\end_inset

LeCun, Y.
 
\emph on
Mnist database of handwritten digits
\emph default
, http://yann.lecun.com/exdb/mnist/
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ref:pypi"

\end_inset


\emph on
PyPi, Python Library
\emph default
, https://pypi.python.org/pypi
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ref:numpy"

\end_inset


\emph on
Numpy
\emph default
, http://www.numpy.org/
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ref:numpyDOC"

\end_inset


\emph on
Numpy
\emph default
 
\emph on
documentation
\emph default
, https://docs.scipy.org/doc/numpy-dev/user/numpy-for-matlab-users.html
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ref:matplotlib"

\end_inset


\emph on
Matplotlib
\emph default
, http://matplotlib.org/
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ref:tensor"

\end_inset


\emph on
TensorFlow
\emph default
, https://www.tensorflow.org/
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ref:tensorGood"

\end_inset

Kuster, D., 
\emph on
The good, bad and ugly of TensorFlow
\emph default
, 
\emph on
KD Nuggets
\emph default
, 2015
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ref:pybrain"

\end_inset


\emph on
PyBrain
\emph default
, http://pybrain.org/
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ref:theano"

\end_inset


\emph on
Theano
\emph default
, http://deeplearning.net/software/theano/
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ref:scikit"

\end_inset


\emph on
Scikit-learn
\emph default
, http://scikit-learn.org/stable/
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ref:scikitWhy"

\end_inset

Lorica, B., 
\emph on
Six reasons why I recommend scikit-learn
\emph default
, https://www.oreilly.com/
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ref:keras"

\end_inset


\emph on
Keras
\emph default
, https://keras.io/
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "ref:opencv"

\end_inset

OpenCV, http://opencv.org/
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "bib:neiger"

\end_inset

Neiger, V.
 
\emph on
Handwritten digits recognition using openCV
\emph default
, Western University, (2015)
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "book:gurney"

\end_inset

Gurney, K.
 An introduction to neural networks, UCL-Press (1997)
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "book:heaton"

\end_inset

Heaton, J.
 Introduction to math of neural networks, Heaton Research, (2012)
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "bib:annealing"

\end_inset

Rere, L.M., Fanany, M.I, Arymurthy, A.M., Simulated annealing algorithm for deep
 learning, Procedia Computer Science, Volume 72, (2015) Pages 137-144
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "bib:CD"

\end_inset

 Cvitanović, P., Davidchack, R.
 L.
 and Siminos, E., On the state space geometry of the Kuramoto-Sivashinsky
 flow in a periodic domain, 
\emph on
SIAM J.
 Appl.
 Dyn.
 Syst.

\emph default
 
\series bold
9
\series default
 (2010), 1–-33.
  
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
addcontentsline{toc}{chapter}{Bibliography}
\end_layout

\end_inset


\end_layout

\end_body
\end_document
